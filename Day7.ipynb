{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fb9628-24be-49c3-9d00-06f14fddbfdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee85a873-e57b-47e7-9c68-6b6a632e8423",
   "metadata": {},
   "source": [
    "## Introduction to Data Science\n",
    "\n",
    "#### University of Redlands - DATA 101\n",
    "#### Prof: Joanna Bieri [joanna_bieri@redlands.edu](mailto:joanna_bieri@redlands.edu)\n",
    "#### [Class Website: data101.joannabieri.com](https://joannabieri.com/data101.html)\n",
    "\n",
    "---------------------------------------\n",
    "# Homework Day 7\n",
    "---------------------------------------\n",
    "\n",
    "GOALS:\n",
    "\n",
    "1. Answer all the questions from the lecture - we will use the scientists data and the grocery data.\n",
    "2. Analyze data about College majors - your first EDA! (Think of this as a practice exam.)\n",
    "\n",
    "----------------------------------------------------------\n",
    "\n",
    "This homework has **9 Questions** and **A Practice Exam**\n",
    "\n",
    "NOTE:\n",
    "The practice exam is intended to give you an idea of what an exam in this class might feel like. Remember you will be expected to work on the exam **independently** and submit your work before we get together to work on the exam in class. **15\\% of your Exam grade will come from what you can do independently** so start practicing now and get help if you need it!."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98531f6b-5ae6-405b-a402-e01105200812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.defaule = 'colab'\n",
    "\n",
    "from itables import show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5d38f2-b324-4884-a230-a1aba61a0fdc",
   "metadata": {},
   "source": [
    "## Lecture Questions\n",
    "\n",
    "First we will import the data about female scientists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cee7d2ad-1b3f-45b7-ad7b-d6302c3f7bd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 11001] getaddrinfo failed>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mgaierror\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\urllib\\request.py:1344\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1343\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1344\u001b[39m     \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTransfer-encoding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\http\\client.py:1338\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1337\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\http\\client.py:1384\u001b[39m, in \u001b[36mHTTPConnection._send_request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1383\u001b[39m     body = _encode(body, \u001b[33m'\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1384\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\http\\client.py:1333\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1332\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1333\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\http\\client.py:1093\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1096\u001b[39m \n\u001b[32m   1097\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\http\\client.py:1037\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\http\\client.py:1472\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1470\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mConnect to a host on a given (SSL) port.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1472\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tunnel_host:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\http\\client.py:1003\u001b[39m, in \u001b[36mHTTPConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1002\u001b[39m sys.audit(\u001b[33m\"\u001b[39m\u001b[33mhttp.client.connect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m.port)\n\u001b[32m-> \u001b[39m\u001b[32m1003\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\socket.py:841\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, all_errors)\u001b[39m\n\u001b[32m    840\u001b[39m exceptions = []\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    842\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\socket.py:978\u001b[39m, in \u001b[36mgetaddrinfo\u001b[39m\u001b[34m(host, port, family, type, proto, flags)\u001b[39m\n\u001b[32m    977\u001b[39m addrlist = []\n\u001b[32m--> \u001b[39m\u001b[32m978\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    979\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[31mgaierror\u001b[39m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mURLError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m file1 = \u001b[33m'\u001b[39m\u001b[33mhttps://joannabieri.com/introdatascience/data/dates.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m DF_dates = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m file2 = \u001b[33m'\u001b[39m\u001b[33mhttps://joannabieri.com/introdatascience/data/professions.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m DF_professions = pd.read_csv(file2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    725\u001b[39m     codecs.lookup_error(errors)\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m ioargs = \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m handle = ioargs.filepath_or_buffer\n\u001b[32m    737\u001b[39m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\site-packages\\pandas\\io\\common.py:384\u001b[39m, in \u001b[36m_get_filepath_or_buffer\u001b[39m\u001b[34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[32m    383\u001b[39m req_info = urllib.request.Request(filepath_or_buffer, headers=storage_options)\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[32m    385\u001b[39m     content_encoding = req.headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Encoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding == \u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\site-packages\\pandas\\io\\common.py:289\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[33;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03mthe stdlib.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequest\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\urllib\\request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\urllib\\request.py:515\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    512\u001b[39m     req = meth(req)\n\u001b[32m    514\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    518\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\urllib\\request.py:532\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    529\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    531\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\urllib\\request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\urllib\\request.py:1392\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1392\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Data101\\Lib\\urllib\\request.py:1347\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1344\u001b[39m         h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[32m   1345\u001b[39m                   encode_chunked=req.has_header(\u001b[33m'\u001b[39m\u001b[33mTransfer-encoding\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m   1346\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1347\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m   1348\u001b[39m     r = h.getresponse()\n\u001b[32m   1349\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[31mURLError\u001b[39m: <urlopen error [Errno 11001] getaddrinfo failed>"
     ]
    }
   ],
   "source": [
    "file1 = 'https://joannabieri.com/introdatascience/data/dates.csv'\n",
    "DF_dates = pd.read_csv(file1)\n",
    "file2 = 'https://joannabieri.com/introdatascience/data/professions.csv'\n",
    "DF_professions = pd.read_csv(file2)\n",
    "file3 = 'https://joannabieri.com/introdatascience/data/works.csv'\n",
    "DF_works = pd.read_csv(file3)\n",
    "show(DF_dates)\n",
    "show(DF_professions)\n",
    "show(DF_works)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac3075a-6e0b-4c0f-b887-520de8c2d98b",
   "metadata": {},
   "source": [
    "**Q1** Are each of these data sets Tidy?\n",
    "\n",
    "***Yes I would say that the data sets are tidy, they all coorespond to the collumns and give information that can be usable.***\n",
    "\n",
    "**Q2** Do they all contain the same number of observations?\n",
    "\n",
    "***No. The first data set has  3 while the other ones have 2, assuming that obeservations means collumns***\n",
    "\n",
    "**Q3** What are the five variables?\n",
    "\n",
    "***Ada Lovelace\t\n",
    "Marie Curie\t\n",
    "Janaki Ammal\t\n",
    "Chien-Shiung Wu\n",
    "Katherine Johnson***\t\n",
    "\n",
    "**Q4** What variable do they have in common - what can we join **on**\n",
    "\n",
    "***The names are all the same***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016a87a9-730c-4847-8a32-86168084a17e",
   "metadata": {},
   "source": [
    "**(Click Here)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e478ec8-d5f3-4d7a-9fbb-ba6a634e8476",
   "metadata": {},
   "source": [
    "## Combining Three Data Sets\n",
    "\n",
    "You need to think about the order and whether or not you want to keep the maximum number of names or only keep names that are in all the data frames.\n",
    "\n",
    "In this case we will try to keep the maximal amount of data - the maximum number of names.\n",
    "\n",
    "1. Combine the professions and works data\n",
    "2. Then add the dates data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c65544-fda4-4795-bc17-1c65aa503cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Combine the professions and works data\n",
    "DF_scientists = pd.merge(DF_professions,DF_works,on='name',how='right')\n",
    "DF_scientists\n",
    "# 2. Then add the dates data\n",
    "DF_scientists = pd.merge(DF_scientists,DF_dates,on='name',how='right')\n",
    "DF_scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b16988-2099-4d00-8f4a-1ae06387dae5",
   "metadata": {},
   "source": [
    "**Q5** What, if anything, would change if you switched to how='right'?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac95fb0-a60d-4fb1-ae12-d9b5ae76584f",
   "metadata": {},
   "source": [
    "**(Click Here)**\n",
    "\n",
    "***Detirmines which side the data is being added to? No changes nothing at all***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e0b2d7-c529-44a5-94b7-8cad5dd408f5",
   "metadata": {},
   "source": [
    "## Combining Two Data Sets - You Try\n",
    "\n",
    "**Q6** Write code that would combine the professions data and the dates data, but drop any names that don't appear in both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6044b2-886c-46aa-ae47-c642c084990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "DF_scientists = pd.merge(DF_professions, DF_works, on='name', how='inner')\n",
    "DF_scientists\n",
    "#inner makes it so the names withing the dataset stay and those not included are dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f60ef2-4067-46c3-8590-1f559274e681",
   "metadata": {},
   "source": [
    "## Combining Three Data Sets - You Try\n",
    "\n",
    "**Q7** Try t\n",
    "o combine the three data sets together (professions, works, and dates) but instead of doing what we did above, see if you can keep only the names that appeared in all three data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1de2725-9dbb-4b1a-a914-db59639d37b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "DF_scientists = (DF_professions.merge(DF_works, on=\"name\", how=\"inner\").merge(DF_dates, on=\"name\", how=\"inner\"))\n",
    "\n",
    "DF_scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d49d89d-10b5-4c4f-8192-2a017494c1bb",
   "metadata": {},
   "source": [
    "## Case study - Grocery Sales\n",
    "\n",
    "Below you will load some data about grocery sales and see how joining or merging data can help us answer questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c786336-cfeb-4597-8449-ed6e01f0e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'https://joannabieri.com/introdatascience/data/purchases.csv'\n",
    "DF_purchases = pd.read_csv(file1)\n",
    "file2 = 'https://joannabieri.com/introdatascience/data/prices.csv'\n",
    "DF_prices = pd.read_csv(file2)\n",
    "show(DF_purchases)\n",
    "show(DF_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5af1fa1-4f7d-4cd4-ac09-e509772e5f57",
   "metadata": {},
   "source": [
    "## Calculate the total revenue\n",
    "\n",
    "**Q8** Given the data above find the total revenue.\n",
    "\n",
    "We will have to join the data frames so that we can see the price of what was sold. So first we look for a common column. In this case both data frames have **item** as a column.\n",
    "\n",
    "Now, think about how to calculate revenue... we need to add up the total money we made, so we need to know the price of each thing sold.\n",
    "\n",
    "**PAUSE - see if you can write some of the code for this before looking at the cells below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c0888-d03e-4ff7-9b66-79fa9c74e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_store = (\n",
    "    DF_purchases\n",
    "    .merge(DF_purchases, on=\"item\", how=\"inner\")\n",
    "    .merge(DF_prices, on=\"item\", how=\"inner\")\n",
    ")\n",
    "\n",
    "DF_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebff5cbc-dbdc-4fec-8eb6-c79edca4e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_store.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1967df-b69d-4a1e-9d97-046ffe56d54c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672d7ea-2c0c-411d-bee7-42a985f1b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bfd299-2f8f-4073-9bff-f2a0bf6b5be0",
   "metadata": {},
   "source": [
    "**See the lecture notes if you need heelp figuring this out!**\n",
    "\n",
    "**Q9** Calculate the revenue per customer? Hint - group by the customer id and then apply the sum()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9f757c-4372-490c-993f-815b1880b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499278e8-0acb-4eba-bfa2-336d0e55adb3",
   "metadata": {},
   "source": [
    "The first step in the process of turning information into knowledge process is to summarize and describe the raw information - the data.\n",
    "In this assignment we explore data on college majors and earnings, specifically the data begin the FiveThirtyEight story [\"The Economic Guide To Picking A College Major\"](https://fivethirtyeight.com/features/the-economic-guide-to-picking-a-college-major/).\n",
    "\n",
    "These data originally come from the American Community Survey (ACS) 2010-2012 Public Use Microdata Series.\n",
    "While this is outside the scope of this assignment, if you are curious about how raw data from the ACS were cleaned and prepared, see [the code](https://github.com/fivethirtyeight/data/blob/master/college-majors/college-majors-rscript.R) FiveThirtyEight authors used.\n",
    "\n",
    "We should also note that there are many considerations that go into picking a major.\n",
    "Earnings potential and employment prospects are two of them, and they are important, but they don't tell the whole story.\n",
    "Keep this in mind as you analyze the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4abc95-54f3-4ac3-829e-04f7db85211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = 'https://joannabieri.com/introdatascience/data/recent-grads.csv'\n",
    "DF_raw = pd.read_csv(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b5ca28-76a8-4bac-b587-9864dae60ffd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DF_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8b7b01-42fe-4200-958c-8034ec4e381e",
   "metadata": {},
   "source": [
    "### 1. Describe the data that you see here.\n",
    "\n",
    "* How many variables?\n",
    "* How man observations?\n",
    "* Are the variables categorical or numerical?\n",
    "* Are there any variables that you don't know what they mean? If so [CLICK HERE - to see the Git Repo for the data where the variables are defined](https://github.com/fivethirtyeight/data/tree/master/college-majors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7582b22d-fe2f-4096-9cab-7eb68317d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283046a0-671b-460d-add7-5f25136c773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac29a401-96dd-4fa0-b731-f44a7248b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84940acb-06aa-4ff9-94f0-7bbb73b6acf6",
   "metadata": {},
   "source": [
    "**(Click Here to Explain your Results)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88705179-450a-442e-9d00-c5e468e4f2ed",
   "metadata": {},
   "source": [
    "### 2. Answer some questions about the data\n",
    "\n",
    "* Which major has the lowest unemployment rate? Show a data frame that answers this question, but only show columns that are useful to the answer.\n",
    "* Which major has the highest percentage of women? Show a data frame that answers this question, but only show columns that are useful to the answer.\n",
    "* How do the distributions of median income compare across major categories?\n",
    "    * First get a value count on what major categories are in the data. What categories are most or least represented?\n",
    "    * Do some summary statistics using the .group_by() command to see the statistics for each major category.\n",
    "    * Make a histogram that explores median income for each of the major categories (facet_col). How did you choose your number of bins?\n",
    "    * Why do we often choose the median, rather than the mean, to describe the typical income of a group of people? Look this up online if you don't know the answer!\n",
    "    * Answer the question: Which major category has the highest typical (you'll need to decide what this means) median income?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4bb632-db11-48fc-bf24-efc6eeb35542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "DF_raw.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b8267-9765-4e98-842d-22e0c4ea316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_DF = DF_raw[['Major','Unemployment_rate']]\n",
    "new_DF.sort_values(by='Unemployment_rate').head(10)\n",
    "#tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b0409a-f4e3-4e0c-9277-afd6edd940a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coll = ['ShareWomen', 'Major']\n",
    "DF_raw[coll].sort_values('ShareWomen').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd14d5-3337-41f6-8382-735464af6ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAME AS ABOVE BUT USUING MATH (ALSO CREATES NEW COLLUMN)\n",
    "\n",
    "collu = ['Major', 'Total', 'Women']\n",
    "DF_percent = DF_raw.copy()\n",
    "\n",
    "DF_percent['Women_Participation'] = (DF_percent['Women'] / DF_percent['Total'])\n",
    "DF_percent[['Major','Women_Participation']].sort_values(by='Women_Participation', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95157cc2-6128-4e34-bedf-7a1ecd757a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How do the distributions of median income compare across major categories?\n",
    "#First get a value count on what major categories are in the data. What categories are most or least represented?\n",
    "DF_raw['Major_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45cc9a-487b-40a5-9592-f206bdc02b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_raw.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37454be-0c99-413a-875a-88338c89f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do some summary statistics using the .group_by() command to see the statistics for each major category.\n",
    "DF_raw.groupby('Major_category')[['Unemployment_rate','Low_wage_jobs','College_jobs']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d95e1e1-0b58-4bf7-92c7-a4200e72cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a histogram that explores median income for each of the major categories (facet_col). How did you choose your number of bins?\n",
    "fig = px.histogram(DF_raw,\n",
    "                   nbins=9,\n",
    "                   x='Major_category',\n",
    "                   color='Unemployment_rate',\n",
    "                   opacity=0.5,\n",
    "                  )\n",
    "\n",
    "\n",
    "fig.show()\n",
    "#Why do we often choose the median, rather than the mean, to describe the typical income of a group of people? Look this up online if you don't know the answer!\n",
    "#Answer the question: Which major category has the highest typical (you'll need to decide what this means) median income?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a04452-a94c-4e80-82a3-5d572c91c0a3",
   "metadata": {},
   "source": [
    "**(Click Here to Explain your Results)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578ed061-38d7-4372-9e51-5165bb35650f",
   "metadata": {},
   "source": [
    "### 3. More complicated questions\n",
    "\n",
    "* Are all STEM fields the same in terms job opportunities?\n",
    "    * Assume the following are STEM major categories\n",
    "    \n",
    "  ``` [\"Biology & Life Science\", \"Computers & Mathematics\", \"Engineering\",\"Physical Sciences\"]```\n",
    "  \n",
    "    * Create a DataFrame (using a mask) so you only look at STEM majors.\n",
    "    * Which STEM majors have median salaries equal to or less than the median for all majors' median earnings?\n",
    "* What types of majors do women tend to major in?\n",
    "    * Create a scatterplot of median income vs. proportion of women in that major, coloured by whether the major is in a STEM field or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7316846f-30a4-468f-8112-4378d21555b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mask needs to include the 4 majors\n",
    "\n",
    "mask = (DF_raw['Major_category']=='Biology & Life Science') | (DF_raw['Major_category']=='Computers & Mathematics') | (DF_raw['Major_category']=='Engineering') | (DF_raw['Major_category']=='Physical Sciences')\n",
    "DF_stem = DF_raw[mask]\n",
    "DF_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7b42dc-a467-453c-8e0d-f83b6f731858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#median for total, stem, individual stem\n",
    "mall = DF_raw['Median'].median()\n",
    "print(mall)\n",
    "mstem = DF_stem['Median'].median()\n",
    "print(mstem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df73092-42d7-4d20-8c20-ddad50899cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[\"Biology & Life Science\", \"Computers & Mathematics\", \"Engineering\",\"Physical Sciences\"]\n",
    "mstem = DF_stem['Median'].median()\n",
    "print(mstem)\n",
    "\n",
    "major_cat = 'Biology & Life Science'\n",
    "mask = DF_stem['Major_category'] == major_cat\n",
    "cat_median = DF_stem[mask]['Median'].median()\n",
    "print(cat_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e77cc2f-655b-4fe5-9e5d-63f153b49fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_raw.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b71214d-d407-4a51-a03a-a0de46e110eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DF_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m mcol = [\u001b[33m'\u001b[39m\u001b[33mMajor\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMajor_category\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mShareWomen\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mDF_raw\u001b[49m[mcol].sort_values(by = \u001b[33m'\u001b[39m\u001b[33mShareWomen\u001b[39m\u001b[33m'\u001b[39m, ascending = \u001b[38;5;28;01mFalse\u001b[39;00m).head(\u001b[32m25\u001b[39m)\n\u001b[32m      5\u001b[39m fig = px.scatter(DF_raw, x=\u001b[33m'\u001b[39m\u001b[33mMedian\u001b[39m\u001b[33m'\u001b[39m, y=\u001b[33m'\u001b[39m\u001b[33mShareWomen\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'DF_raw' is not defined"
     ]
    }
   ],
   "source": [
    "mcol = ['Major', 'Major_category', 'ShareWomen']\n",
    "\n",
    "DF_raw[mcol].sort_values(by = 'ShareWomen', ascending = False).head(25)\n",
    "\n",
    "fig = px.scatter(DF_raw, x='Median', y='ShareWomen')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba0beea-76f3-465c-b76a-876f1ecdb512",
   "metadata": {},
   "source": [
    "**(Click Here to Explain your Results)**\n",
    "\n",
    "***The median is overall higher but not all stem is created equal. bio + stem is 36300.0, which is slightly higher than the median for all which is 36000.0.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206276d9-3380-4937-96e0-0e420a5781e4",
   "metadata": {},
   "source": [
    "### 4. Ask a question of interest to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "153afe3f-7087-46c0-848b-a5c5bc1e15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1b5e13-c89e-49ec-89a4-a779bbe2f2c1",
   "metadata": {},
   "source": [
    "**(Click Here to Explain your Results)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de91ea98-3baf-4694-962b-6ca7a2ee0c11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7574df13-ae0f-4e26-8f60-1404fa5fd666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071cf740-7d40-46f0-8736-c8338fbdc8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1604facc-0ff2-4ebe-a1c7-86217d951752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b466716e-d31c-441a-a0e8-97ba83f63385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d94ccc2-3f42-44dd-8040-ea5f88e7cf13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b0aaa1-e75b-4b2a-991d-e2fe515fe61c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b2e68a-0327-4951-80f8-482c5629efc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
